{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL USING ROGUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jscadenas/redditscrape/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\n",
    "            \"summarization\",\n",
    "            model = \"../models/model2\",\n",
    "            tokenizer = \"../models/model2\",\n",
    "        )\n",
    "        \n",
    "def summarize(text, prompt):\n",
    "    inputs = f\"{prompt}: {text}\"\n",
    "    input_tokens = summarizer.tokenizer.encode(inputs, truncation=False)\n",
    "    input_len = len(input_tokens)\n",
    "    max_length = min(input_len * 2, 1024)\n",
    "    min_length = max(32, input_len // 4)\n",
    "    summary = summarizer(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "    )\n",
    "    return summary[0]['summary_text']\n",
    "    \n",
    "def process_data(response, prompt):\n",
    "    post_content = response[0]['data']['children'][0]['data'].get('selftext', '')\n",
    "    comments = []\n",
    "    for comment in response[1]['data']['children']:\n",
    "        if 'body' in comment['data']:\n",
    "            comments.append(comment['data']['body'])\n",
    "    comments_all = ' '.join(comments)\n",
    "\n",
    "    post_summary = summarize(post_content, prompt)\n",
    "    comments_summary = summarize(comments_all, prompt)\n",
    "\n",
    "    return {\n",
    "        \"post_summary\": post_summary,\n",
    "        \"comments_summary\": comments_summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the reddit post and summarize it then save the summary in another json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 274, but your input_length is only 137. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=68)\n",
      "Your max_length is set to 380, but your input_length is only 190. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to summary.json\n"
     ]
    }
   ],
   "source": [
    "with open('../data/response.json') as file:\n",
    "    reddit_post = json.load(file)\n",
    "\n",
    "summary = process_data(reddit_post, \"Summarize and highlight popular brands\")\n",
    "\n",
    "with open('../data/summary.json', 'w') as file:\n",
    "    json.dump(summary, file, indent=4)\n",
    "print(\"Summary saved to summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify by printing the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Summary:\n",
      " {\"title\": \"Budget for a New Chair with Adjustable Headrest and Armrest\", \"selftext\": \"The user is looking for a new chair with an adjustable headrest, armrest, chair height, and a lumbar pillow with mesh material. They mention a budget of P3,000-P4,000 and highlight popular brands.\", \"comments\": [\"Users provide feedback on the chair's specifications and suggest alternative options.\", \"Some users suggest reaching out to influencers for recommendations on speakerphones or headphones for better long-distance communication.\", \"The sentiment is positive, with users appreciating the user's effort to find a chair and offering helpful suggestions for its design.\"], \"sentiment\": \" the sentiment is encouraging and supportive, with Users sharing their own search experiences and offering suggestions for additional features on chairs and speakers.\"}\n",
      "\n",
      "Comments Summary:\n",
      " {\"title\": \"Budget-friendly office chair suggestions\", \"selftext\": {\"overview\": \"The post provides a budget-friendly option for purchasing a used desktop chair, highlighting popular brands like Steelcase and Sihoo as examples. The user shares their own experience with buying good chairs under budget, highlighting the benefits of buying used or refurbished models.\", \"suggestions\": [\"Used Steelcase chairs priced at around 4k PHP on Facebook Marketplace with a guarantee.\", \"Carousell offers office chairs for around 1.5k PHP, which is within the budget.\", \"The OP shares a positive experience with purchasing a SihOO m57 and an Ergo Prime Mesh chair for around 8-9k PHP each, describing them as the best desktop chairs they've ever bought.\", \"There are 3-5k chairs out there, and the OP advises trying different platforms to find good deals.\"], \"comments\": [\"Users share their own experiences with buying chairs and advise the OP on where to buy and how to proceed.\", \"Some users mention limited budget options and recommend specific brands or platforms based on their previous experiences.\", \" The sentiment is mixed, with users appreciating the OP's experience but also sharing their own concerns about the quality of used chairs and the wide variety of models available.\"]}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Post Summary:\\n\", summary[\"post_summary\"])\n",
    "print(\"\\nComments Summary:\\n\", summary[\"comments_summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix the json files (the output summary files are not formatted properly (json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/summary.json', 'r') as file:\n",
    "    generated_summaries = file.read()\n",
    "\n",
    "with open('../data/reference.json', 'r') as file:\n",
    "    reference_summaries = file.read()\n",
    "\n",
    "def fix_json(jsonfile, path):\n",
    "    improper_json = jsonfile\n",
    "\n",
    "    fixed_json = json.loads(improper_json)\n",
    "\n",
    "    fixed_post_summary = json.loads(fixed_json['post_summary'])\n",
    "    fixed_comments_summary = json.loads(fixed_json['comments_summary'])\n",
    "\n",
    "    fixed_json['post_summary'] = fixed_post_summary\n",
    "    fixed_json['comments_summary'] = fixed_comments_summary\n",
    "\n",
    "    print(json.dumps(fixed_json, indent=4))\n",
    "\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(fixed_json, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix the formatting of the generated summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"post_summary\": {\n",
      "        \"title\": \"Budget for a New Chair with Adjustable Headrest and Armrest\",\n",
      "        \"selftext\": \"The user is looking for a new chair with an adjustable headrest, armrest, chair height, and a lumbar pillow with mesh material. They mention a budget of P3,000-P4,000 and highlight popular brands.\",\n",
      "        \"comments\": [\n",
      "            \"Users provide feedback on the chair's specifications and suggest alternative options.\",\n",
      "            \"Some users suggest reaching out to influencers for recommendations on speakerphones or headphones for better long-distance communication.\",\n",
      "            \"The sentiment is positive, with users appreciating the user's effort to find a chair and offering helpful suggestions for its design.\"\n",
      "        ],\n",
      "        \"sentiment\": \" the sentiment is encouraging and supportive, with Users sharing their own search experiences and offering suggestions for additional features on chairs and speakers.\"\n",
      "    },\n",
      "    \"comments_summary\": {\n",
      "        \"title\": \"Budget-friendly office chair suggestions\",\n",
      "        \"selftext\": {\n",
      "            \"overview\": \"The post provides a budget-friendly option for purchasing a used desktop chair, highlighting popular brands like Steelcase and Sihoo as examples. The user shares their own experience with buying good chairs under budget, highlighting the benefits of buying used or refurbished models.\",\n",
      "            \"suggestions\": [\n",
      "                \"Used Steelcase chairs priced at around 4k PHP on Facebook Marketplace with a guarantee.\",\n",
      "                \"Carousell offers office chairs for around 1.5k PHP, which is within the budget.\",\n",
      "                \"The OP shares a positive experience with purchasing a SihOO m57 and an Ergo Prime Mesh chair for around 8-9k PHP each, describing them as the best desktop chairs they've ever bought.\",\n",
      "                \"There are 3-5k chairs out there, and the OP advises trying different platforms to find good deals.\"\n",
      "            ],\n",
      "            \"comments\": [\n",
      "                \"Users share their own experiences with buying chairs and advise the OP on where to buy and how to proceed.\",\n",
      "                \"Some users mention limited budget options and recommend specific brands or platforms based on their previous experiences.\",\n",
      "                \" The sentiment is mixed, with users appreciating the OP's experience but also sharing their own concerns about the quality of used chairs and the wide variety of models available.\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "fix_json(generated_summaries, '../data/summary.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the results using ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: [{'rouge-1': {'r': 0.5766423357664233, 'p': 0.4340659340659341, 'f': 0.4952978007421311}, 'rouge-2': {'r': 0.2930232558139535, 'p': 0.20723684210526316, 'f': 0.24277456162102168}, 'rouge-l': {'r': 0.5620437956204379, 'p': 0.4230769230769231, 'f': 0.4827586157891531}}]\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "\n",
    "results = rouge.get_scores(generated_summaries, reference_summaries)\n",
    "\n",
    "print(f\"ROUGE Scores: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ROGUE-1 SCORES:**\n",
    "- **Recall (r)** = 57.66%\n",
    "- **Precision (p)** = 43.41%\n",
    "- **F1-Score (f)** = 49.53%\n",
    "\n",
    "### **ROUGE-2 SCORES:**\n",
    "- **Recall (r)** = 29.30%\n",
    "- **Precision (p)** = 20.72%\n",
    "- **F1-Score (f)** = 24.27%\n",
    "\n",
    "### **ROUGE-L SCORES:**\n",
    "- **Recall (r)** = 56.20%\n",
    "- **Precision (p)** = 42.30%\n",
    "- **F1-Score (f)** = 48.28%\n",
    "\n",
    "<br>\n",
    "\n",
    "**ROUGE-1:** also known as unigram, measures the overlap of unigrams (individual words) between the generated summary and the reference summary. It calculates the proportion of words in the generated summary that are also present in the reference summary. Example: Reference text: “The cat is on the rug” Generated text: “The dog is on the rug” ROUGE-1 = 3/5 = 0.6.\n",
    "\n",
    "**ROUGE-2:** also known as bigram, measures the overlap of bigrams (pairs of consecutive words) between the generated summary and the reference summary. It calculates the proportion of bigrams in the generated summary that are also present in the reference summary.\n",
    "\n",
    "**ROUGE-L:** measures the similarity between the word sequence of the generated abstract and the reference abstract using the longest sequence of words in common. Unlike ROUGE-1 and ROUGE-2, which use a simple word count approach, ROUGE-L uses a string matching approach.\n",
    "\n",
    "**Source:** https://fabianofalcao.medium.com/metrics-for-evaluating-summarization-of-texts-performed-by-transformers-how-to-evaluate-the-b3ce68a309c3\n",
    "\n",
    "### **CONCLUSIONS**\n",
    "**ROGUE-1 SCORE:** The ROUGE-1 score indicates that the model is fairly good at capturing individual words (unigrams) from the reference summaries. With a recall of 57.66%, the model captures more than half of the relevant words from the reference summaries, which suggests that it's effectively capturing key content. The precision of 43.41% indicates that a significant portion of the generated summary’s words also appear in the reference, but there may be some additional, irrelevant words included. The F1-score of 49.53% shows that, overall, there’s a fairly good balance between recall and precision, although there's still room to increase both aspects for better results.\n",
    "\n",
    "**ROGUE-2 SCORE:** The ROUGE-2 score, which focuses on bigram overlap, is considerably lower than ROUGE-1. The recall of 29.30% indicates that the model captures roughly 30% of the bigrams from the reference summaries, which is a moderate result but suggests that the model may not be fully preserving the structural relationships between words. The precision of 20.72% suggests that the generated summaries might include bigrams that are not present in the reference summaries. The F1-score of 24.27% is relatively low, which may indicate that the model needs improvement in capturing bigram patterns in the summaries. This is common in summarization tasks, as producing high-quality bigram overlap is challenging.\n",
    "\n",
    "**ROGUE-l SCORE:** The ROUGE-L score, which focuses on the longest common subsequence (LCS), shows that the model is able to capture the overall structure of the reference summaries quite well. The recall of 56.20% suggests that a large portion of the key sequences (order-preserving) from the reference summaries appear in the generated summaries, indicating good coherence. The precision of 42.30% shows that the model does well in maintaining relevant sequences in the generated summary but could further reduce redundant or non-informative sequences. The F1-score of 48.28% indicates a solid performance in preserving the flow and structure of the original text.\n",
    "\n",
    "### **SUMMARY**  \n",
    "- The ROUGE-1 score is strong, indicating that the model is capturing individual words well, which is important for summarizing the key points of Reddit posts. This suggests the model is effectively identifying the core content from the original Reddit discussions.\n",
    "\n",
    "- The ROUGE-2 score is relatively low, suggesting that the model struggles with preserving the structure and sequence of words, which is crucial for generating coherent summaries of Reddit posts where sentence flow and the connection between ideas are important.\n",
    "\n",
    "- The ROUGE-L score shows that the model is effectively capturing meaningful sequences and maintaining coherence in the summaries. This is a positive outcome for summarizing Reddit posts, where keeping the overall message and flow intact is important.\n",
    "\n",
    "While the model performs well in certain areas (particularly with ROUGE-1 and ROUGE-L), there is room for improvement, especially with the ROUGE-2 score. Improving bigram overlap could enhance the fluency and structure of the summaries, leading to more readable and coherent summaries of Reddit posts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
